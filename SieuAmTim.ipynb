{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SieuAmTim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quangtrung0220/SieuAmTim/blob/master/SieuAmTim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOR4tIyWxCtG"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import namedtuple\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVMBQrJ-TkpR",
        "outputId": "b795ff2e-4c0e-4497-a409-9aff758a482a"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Ekbuc8UWLr"
      },
      "source": [
        "def get_clases():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "\n",
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "def prepare_data():\n",
        "  transform_train = transforms.Compose([\n",
        "    transforms.Resize((224,224)),                                    \n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "  transform_test = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "  trainset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/train', transform=transform_train)\n",
        "  testset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/test', transform=transform_test)\n",
        "  return TrainTest(train=trainset, test=testset)\n",
        "\n",
        "def prepare_loader(datasets):\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=35, shuffle=True, num_workers=4)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=35, shuffle=False, num_workers=4)\n",
        "  return TrainTest(train=trainloader, test=testloader)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBdgazuRRB3K"
      },
      "source": [
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  true_result = []\n",
        "  pred_result = []\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 18\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    true_result += list(labels.cpu().numpy())\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    pred_result += list(predicted.cpu().numpy())\n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % reporting_steps == reporting_steps-1:\n",
        "      print(f\"Epoch {epoch} step {i} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "  return pred_result, true_result\n",
        "\n",
        "def test_epoch(epoch, model, loader, device):\n",
        "  ytrue = []\n",
        "  ypred = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    \n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "      ytrue += list(labels.cpu().numpy())\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "\n",
        "  return ypred, ytrue"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "YA-A25O0RLTG",
        "outputId": "593653d6-54d1-4f23-b915-4c640cc70384"
      },
      "source": [
        "def main(PATH='./model.pth', model_in=''):\n",
        "  classes = get_clases()\n",
        "  datasets = prepare_data()\n",
        "  # img, label = datasets.train[0]\n",
        "  # plt.imshow(img)\n",
        "  # print(classes[label], img.size)\n",
        "  # print('train', len(datasets.train), 'test', len(datasets.test))\n",
        "  \n",
        "  loaders = prepare_loader(datasets)\n",
        "\n",
        "  # images, labels = iter(loaders.train).next()\n",
        "  # print(images.shape, labels.shape)\n",
        "\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # model = ResNet50().to(device)\n",
        "  # model = VGG16().to(device)\n",
        "  # images, labels = iter(loaders.train).next()\n",
        "  # outputs = model(images)\n",
        "  # print(outputs.shape)\n",
        "  # print(outputs[0])\n",
        "  # _, predicted = torch.max(outputs, dim=1)\n",
        "  # print(predicted)\n",
        "  # imshow(images, labels, predicted, classes)\n",
        "\n",
        "  if model_in == 'vgg16':\n",
        "    model = torchvision.models.vgg16()\n",
        "    model.classifier[6] = torch.nn.modules.linear.Linear(in_features=4096, out_features=3, bias=True)\n",
        "    if torch.cuda.is_available():\n",
        "      model.to(device=device)\n",
        "  elif model_in == 'resnet50':\n",
        "    model = torchvision.models.resnet50(pretrained=False, progress=False)\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=2048, out_features=3, bias=True)  \n",
        "    if torch.cuda.is_available():\n",
        "      model.to(device=device)\n",
        "  elif model_in == 'desnet':\n",
        "    model = torchvision.models.densenet121(pretrained=False, progress=False)\n",
        "    model.classifier = torch.nn.modules.linear.Linear(in_features=1024, out_features=3, bias=True)\n",
        "    if torch.cuda.is_available():\n",
        "      model.to(device=device)\n",
        "  else:\n",
        "    pass  \n",
        "\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "  for epoch in range(10):\n",
        "    print(f'Epoch {epoch} report: ')\n",
        "    \n",
        "    pred_result, true_result = train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    print('Train report: ')\n",
        "    print(classification_report(true_result, pred_result, target_names=classes))\n",
        "\n",
        "    print('Test report: ')\n",
        "    ypred, ytrue = test_epoch(epoch, model, loaders.test, device)\n",
        "    print(classification_report(ytrue, ypred, target_names=classes))\n",
        "\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = main(model_in='desnet')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 report: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2254fa7a0d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'desnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-2254fa7a0d82>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(PATH, model_in)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch} report: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mpred_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train report: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e15aa867082e>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, model, loader, loss_func, optimizer, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mreporting_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYppnP7aRinF",
        "outputId": "48948bf4-ba95-4056-b9ea-bb4b48984574"
      },
      "source": [
        "! git\n",
        "! git init\n",
        "! git clone https://github.com/quangtrung0220/SieuAmTim.git\n",
        "! pwd\n",
        "%cd SieuAmTim/\n",
        "! gitgit remote -v\n",
        "! git status"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n",
            "           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n",
            "           [-p | --paginate | --no-pager] [--no-replace-objects] [--bare]\n",
            "           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n",
            "           <command> [<args>]\n",
            "\n",
            "These are common Git commands used in various situations:\n",
            "\n",
            "start a working area (see also: git help tutorial)\n",
            "   clone      Clone a repository into a new directory\n",
            "   init       Create an empty Git repository or reinitialize an existing one\n",
            "\n",
            "work on the current change (see also: git help everyday)\n",
            "   add        Add file contents to the index\n",
            "   mv         Move or rename a file, a directory, or a symlink\n",
            "   reset      Reset current HEAD to the specified state\n",
            "   rm         Remove files from the working tree and from the index\n",
            "\n",
            "examine the history and state (see also: git help revisions)\n",
            "   bisect     Use binary search to find the commit that introduced a bug\n",
            "   grep       Print lines matching a pattern\n",
            "   log        Show commit logs\n",
            "   show       Show various types of objects\n",
            "   status     Show the working tree status\n",
            "\n",
            "grow, mark and tweak your common history\n",
            "   branch     List, create, or delete branches\n",
            "   checkout   Switch branches or restore working tree files\n",
            "   commit     Record changes to the repository\n",
            "   diff       Show changes between commits, commit and working tree, etc\n",
            "   merge      Join two or more development histories together\n",
            "   rebase     Reapply commits on top of another base tip\n",
            "   tag        Create, list, delete or verify a tag object signed with GPG\n",
            "\n",
            "collaborate (see also: git help workflows)\n",
            "   fetch      Download objects and refs from another repository\n",
            "   pull       Fetch from and integrate with another repository or a local branch\n",
            "   push       Update remote refs along with associated objects\n",
            "\n",
            "'git help -a' and 'git help -g' list available subcommands and some\n",
            "concept guides. See 'git help <command>' or 'git help <concept>'\n",
            "to read about a specific subcommand or concept.\n",
            "Reinitialized existing Git repository in /content/SieuAmTim/SieuAmTim/.git/\n",
            "Cloning into 'SieuAmTim'...\n",
            "warning: You appear to have cloned an empty repository.\n",
            "/content/SieuAmTim/SieuAmTim\n",
            "/content/SieuAmTim/SieuAmTim/SieuAmTim\n",
            "/bin/bash: gitgit: command not found\n",
            "On branch master\n",
            "\n",
            "No commits yet\n",
            "\n",
            "nothing to commit (create/copy files and use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY82KJPBOWFh",
        "outputId": "0ff68ba0-2d12-4171-9a24-e73c51905120"
      },
      "source": [
        "class VGG16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.features = self._make_features()\n",
        "    self.classification_head = nn.Linear(in_features=512, out_features=3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.features(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.classification_head(out)\n",
        "    return out\n",
        "\n",
        "  def _make_features(self):\n",
        "    config = [64,64,'MP',128,128,'MP',256,256,256,'MP',512,512,512,'MP',512,512,512,'MP']\n",
        "    layers = []\n",
        "    c_in = 3\n",
        "    for c in config:\n",
        "      if c == 'MP':\n",
        "        layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "      else:\n",
        "        layers += [nn.Conv2d(in_channels=c_in, out_channels=c, kernel_size=3, stride=1, padding=1),\n",
        "                   nn.BatchNorm2d(num_features=c),\n",
        "                   nn.ReLU6(inplace=True)]\n",
        "        c_in = c\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        \n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        \n",
        "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        \n",
        "        #downsample if needed\n",
        "        if self.i_downsample is not None:\n",
        "            identity = self.i_downsample(identity)\n",
        "        #add identity\n",
        "        x+=identity\n",
        "        x=self.relu(x)\n",
        "        \n",
        "        return x\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
        "        \n",
        "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
        "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
        "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
        "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
        "        ii_downsample = None\n",
        "        layers = []\n",
        "        \n",
        "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
        "            ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "            \n",
        "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
        "        self.in_channels = planes*ResBlock.expansion\n",
        "        \n",
        "        for i in range(blocks-1):\n",
        "            layers.append(ResBlock(self.in_channels, planes))\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "def ResNet50(num_classes=3, channels=3):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 report: \n",
            "Epoch 0 step 17 ave_loss 1.0953\n",
            "Epoch 0 step 35 ave_loss 0.8687\n",
            "Epoch 0 step 53 ave_loss 0.6322\n",
            "Epoch 0 step 71 ave_loss 0.4065\n",
            "Epoch 0 step 89 ave_loss 0.3050\n",
            "Epoch 0 step 107 ave_loss 0.2538\n",
            "Epoch 0 step 125 ave_loss 0.1551\n",
            "Epoch 0 step 143 ave_loss 0.2175\n",
            "Epoch 0 step 161 ave_loss 0.2780\n",
            "Epoch 0 step 179 ave_loss 0.1242\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.81      0.83      0.82      2377\n",
            "          3C       0.83      0.80      0.81      2309\n",
            "          4C       0.83      0.84      0.83      2031\n",
            "\n",
            "    accuracy                           0.82      6717\n",
            "   macro avg       0.82      0.82      0.82      6717\n",
            "weighted avg       0.82      0.82      0.82      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.27      1.00      0.43       409\n",
            "          3C       1.00      0.06      0.12       367\n",
            "          4C       1.00      0.10      0.18       831\n",
            "\n",
            "    accuracy                           0.32      1607\n",
            "   macro avg       0.76      0.39      0.24      1607\n",
            "weighted avg       0.81      0.32      0.23      1607\n",
            "\n",
            "Epoch 1 report: \n",
            "Epoch 1 step 17 ave_loss 0.0498\n",
            "Epoch 1 step 35 ave_loss 0.0487\n",
            "Epoch 1 step 53 ave_loss 0.0267\n",
            "Epoch 1 step 71 ave_loss 0.0191\n",
            "Epoch 1 step 89 ave_loss 0.0150\n",
            "Epoch 1 step 107 ave_loss 0.0054\n",
            "Epoch 1 step 125 ave_loss 0.0045\n",
            "Epoch 1 step 143 ave_loss 0.0037\n",
            "Epoch 1 step 161 ave_loss 0.0050\n",
            "Epoch 1 step 179 ave_loss 0.0036\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      0.99      0.99      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.65      0.81      0.72       409\n",
            "          3C       0.63      0.91      0.75       367\n",
            "          4C       1.00      0.68      0.81       831\n",
            "\n",
            "    accuracy                           0.76      1607\n",
            "   macro avg       0.76      0.80      0.76      1607\n",
            "weighted avg       0.82      0.76      0.77      1607\n",
            "\n",
            "Epoch 2 report: \n",
            "Epoch 2 step 17 ave_loss 0.0037\n",
            "Epoch 2 step 35 ave_loss 0.0025\n",
            "Epoch 2 step 53 ave_loss 0.0017\n",
            "Epoch 2 step 71 ave_loss 0.0056\n",
            "Epoch 2 step 89 ave_loss 0.0049\n",
            "Epoch 2 step 107 ave_loss 0.0127\n",
            "Epoch 2 step 125 ave_loss 0.0056\n",
            "Epoch 2 step 143 ave_loss 0.0104\n",
            "Epoch 2 step 161 ave_loss 0.0112\n",
            "Epoch 2 step 179 ave_loss 0.0110\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      1.00      1.00      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.59      0.65      0.62       409\n",
            "          3C       0.50      0.97      0.66       367\n",
            "          4C       1.00      0.52      0.69       831\n",
            "\n",
            "    accuracy                           0.66      1607\n",
            "   macro avg       0.69      0.72      0.65      1607\n",
            "weighted avg       0.78      0.66      0.66      1607\n",
            "\n",
            "Epoch 3 report: \n",
            "Epoch 3 step 17 ave_loss 0.0157\n",
            "Epoch 3 step 35 ave_loss 0.0097\n",
            "Epoch 3 step 53 ave_loss 0.0100\n",
            "Epoch 3 step 71 ave_loss 0.0061\n",
            "Epoch 3 step 89 ave_loss 0.0018\n",
            "Epoch 3 step 107 ave_loss 0.0029\n",
            "Epoch 3 step 125 ave_loss 0.0008\n",
            "Epoch 3 step 143 ave_loss 0.0017\n",
            "Epoch 3 step 161 ave_loss 0.0015\n",
            "Epoch 3 step 179 ave_loss 0.0066\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      1.00      1.00      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.94      0.78      0.85       409\n",
            "          3C       0.49      0.94      0.64       367\n",
            "          4C       1.00      0.67      0.80       831\n",
            "\n",
            "    accuracy                           0.76      1607\n",
            "   macro avg       0.81      0.80      0.77      1607\n",
            "weighted avg       0.87      0.76      0.78      1607\n",
            "\n",
            "Epoch 4 report: \n",
            "Epoch 4 step 17 ave_loss 0.0024\n",
            "Epoch 4 step 35 ave_loss 0.0012\n",
            "Epoch 4 step 53 ave_loss 0.0011\n",
            "Epoch 4 step 71 ave_loss 0.0012\n",
            "Epoch 4 step 89 ave_loss 0.0007\n",
            "Epoch 4 step 107 ave_loss 0.0006\n",
            "Epoch 4 step 125 ave_loss 0.0005\n",
            "Epoch 4 step 143 ave_loss 0.0005\n",
            "Epoch 4 step 161 ave_loss 0.0004\n",
            "Epoch 4 step 179 ave_loss 0.0003\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      1.00      1.00      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.74      0.81      0.78       409\n",
            "          3C       0.65      0.88      0.74       367\n",
            "          4C       1.00      0.79      0.88       831\n",
            "\n",
            "    accuracy                           0.82      1607\n",
            "   macro avg       0.80      0.83      0.80      1607\n",
            "weighted avg       0.85      0.82      0.82      1607\n",
            "\n",
            "Epoch 5 report: \n",
            "Epoch 5 step 17 ave_loss 0.0008\n",
            "Epoch 5 step 35 ave_loss 0.0003\n",
            "Epoch 5 step 53 ave_loss 0.0010\n",
            "Epoch 5 step 71 ave_loss 0.0004\n",
            "Epoch 5 step 89 ave_loss 0.0004\n",
            "Epoch 5 step 107 ave_loss 0.0005\n",
            "Epoch 5 step 125 ave_loss 0.0005\n",
            "Epoch 5 step 143 ave_loss 0.0003\n",
            "Epoch 5 step 161 ave_loss 0.0004\n",
            "Epoch 5 step 179 ave_loss 0.0003\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      1.00      1.00      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.78      0.81      0.80       409\n",
            "          3C       0.66      0.86      0.75       367\n",
            "          4C       1.00      0.85      0.92       831\n",
            "\n",
            "    accuracy                           0.84      1607\n",
            "   macro avg       0.82      0.84      0.82      1607\n",
            "weighted avg       0.87      0.84      0.85      1607\n",
            "\n",
            "Epoch 6 report: \n",
            "Epoch 6 step 17 ave_loss 0.0004\n",
            "Epoch 6 step 35 ave_loss 0.0004\n",
            "Epoch 6 step 53 ave_loss 0.0005\n",
            "Epoch 6 step 71 ave_loss 0.0003\n",
            "Epoch 6 step 89 ave_loss 0.0005\n",
            "Epoch 6 step 107 ave_loss 0.0007\n",
            "Epoch 6 step 125 ave_loss 0.0020\n",
            "Epoch 6 step 143 ave_loss 0.0006\n",
            "Epoch 6 step 161 ave_loss 0.0002\n",
            "Epoch 6 step 179 ave_loss 0.0011\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      1.00      1.00      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.78      0.80      0.79       409\n",
            "          3C       0.67      0.88      0.76       367\n",
            "          4C       0.99      0.84      0.91       831\n",
            "\n",
            "    accuracy                           0.84      1607\n",
            "   macro avg       0.81      0.84      0.82      1607\n",
            "weighted avg       0.86      0.84      0.84      1607\n",
            "\n",
            "Epoch 7 report: \n",
            "Epoch 7 step 17 ave_loss 0.0004\n",
            "Epoch 7 step 35 ave_loss 0.0005\n",
            "Epoch 7 step 53 ave_loss 0.0004\n",
            "Epoch 7 step 71 ave_loss 0.0003\n",
            "Epoch 7 step 89 ave_loss 0.0005\n",
            "Epoch 7 step 107 ave_loss 0.0007\n",
            "Epoch 7 step 125 ave_loss 0.0007\n",
            "Epoch 7 step 143 ave_loss 0.0005\n",
            "Epoch 7 step 161 ave_loss 0.0006\n",
            "Epoch 7 step 179 ave_loss 0.0002\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      1.00      1.00      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.80      0.81      0.80       409\n",
            "          3C       0.61      0.89      0.73       367\n",
            "          4C       1.00      0.79      0.88       831\n",
            "\n",
            "    accuracy                           0.82      1607\n",
            "   macro avg       0.80      0.83      0.81      1607\n",
            "weighted avg       0.86      0.82      0.83      1607\n",
            "\n",
            "Epoch 8 report: \n",
            "Epoch 8 step 17 ave_loss 0.0006\n",
            "Epoch 8 step 35 ave_loss 0.0002\n",
            "Epoch 8 step 53 ave_loss 0.0002\n",
            "Epoch 8 step 71 ave_loss 0.0005\n",
            "Epoch 8 step 89 ave_loss 0.0005\n",
            "Epoch 8 step 107 ave_loss 0.0004\n",
            "Epoch 8 step 125 ave_loss 0.0002\n",
            "Epoch 8 step 143 ave_loss 0.0002\n",
            "Epoch 8 step 161 ave_loss 0.0004\n",
            "Epoch 8 step 179 ave_loss 0.0002\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      1.00      1.00      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.82      0.82      0.82       409\n",
            "          3C       0.64      0.88      0.74       367\n",
            "          4C       1.00      0.84      0.91       831\n",
            "\n",
            "    accuracy                           0.84      1607\n",
            "   macro avg       0.82      0.85      0.82      1607\n",
            "weighted avg       0.87      0.84      0.85      1607\n",
            "\n",
            "Epoch 9 report: \n",
            "Epoch 9 step 17 ave_loss 0.0005\n",
            "Epoch 9 step 35 ave_loss 0.0002\n",
            "Epoch 9 step 53 ave_loss 0.0002\n",
            "Epoch 9 step 71 ave_loss 0.0002\n",
            "Epoch 9 step 89 ave_loss 0.0004\n",
            "Epoch 9 step 107 ave_loss 0.0003\n",
            "Epoch 9 step 125 ave_loss 0.0002\n",
            "Epoch 9 step 143 ave_loss 0.0002\n",
            "Epoch 9 step 161 ave_loss 0.0004\n",
            "Epoch 9 step 179 ave_loss 0.0007\n",
            "Train report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       1.00      1.00      1.00      2377\n",
            "          3C       1.00      1.00      1.00      2309\n",
            "          4C       1.00      1.00      1.00      2031\n",
            "\n",
            "    accuracy                           1.00      6717\n",
            "   macro avg       1.00      1.00      1.00      6717\n",
            "weighted avg       1.00      1.00      1.00      6717\n",
            "\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.87      0.81      0.84       409\n",
            "          3C       0.64      0.90      0.75       367\n",
            "          4C       1.00      0.85      0.92       831\n",
            "\n",
            "    accuracy                           0.85      1607\n",
            "   macro avg       0.83      0.85      0.83      1607\n",
            "weighted avg       0.88      0.85      0.86      1607\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rgCHbCeyxakr",
        "outputId": "545a7faf-67ac-4943-c840-6350c45e2a8a"
      },
      "source": [
        "# # # show images\n",
        "# # classes = get_classes()\n",
        "# # imshow(torchvision.utils.make_grid(images))\n",
        "# # print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "def main(PATH='./model.pth'):\n",
        "\n",
        "  loss_tr = [0.8819, 0.4390, 0.2056, 0.1269, 0.0802, 0.0625, 0.0499, \n",
        "          0.0356, 0.0338, 0.0266]\n",
        "          # , 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001,\n",
        "          # 0.0002, 0.0001, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0002, 0.0001, 0.0001, 0.0001]\n",
        "\n",
        "  loss_te = [69, 67, 71, 74, 72, 77, 75, \n",
        "          78, 82, 78, 75, 75]\n",
        "\n",
        "  time = [0,1,2,3,4,5,6,7,8,9]\n",
        "  # ,10,10,11,11,12,12,13,13,14,14,15,15,16,16,17,17,18,18,19,19]        \n",
        "  labels = ['Epoch 0', 'Epoch 1', 'Epoch 2', 'Epoch 3', 'Epoch 4', 'Epoch 5', 'Epoch 6', 'Epoch 7', 'Epoch 8', 'Epoch 9', 'Epoch 10', 'Epoch 11']\n",
        "          # ,\n",
        "          # '10 - step 17', '10 - step 35', '11 - step 17', '11 - step 35', '12 - step 17', '12 - step 35', '13 - step 17', '13 - step 35', '14 - step 17', '14 - step 35',\n",
        "          # '15 - step 17', '15 - step 35', '17 - step 17', '17 - step 35', '18 - step 17', '18 - step 35', '19 - step 17', '19 - step 35']\n",
        "\n",
        "  position = []\n",
        "  for i in range(40):\n",
        "    position.append(i)\n",
        "\n",
        "  plt.figure(figsize=(20, 5))\n",
        "  plt.xticks(position, labels)\n",
        "\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss in epoch\")\n",
        "  plt.plot(time, loss_tr)\n",
        "  plt.show()\n",
        "\n",
        "  # plt.figure(figsize=(20, 5))\n",
        "  # plt.xticks(position, labels)\n",
        "\n",
        "  # plt.xlabel(\"Epoch\")\n",
        "  # plt.ylabel(\"Accuracy (%)\")\n",
        "  # plt.plot(time, loss_te)\n",
        "  # plt.show()\n",
        "\n",
        "  print(torchvision.models.resnet50())\n",
        "\n",
        "model = main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}