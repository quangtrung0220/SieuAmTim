{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SieuAmTim.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yHqdaDyviNIb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quangtrung0220/SieuAmTim/blob/master/SieuAmTim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHqdaDyviNIb"
      },
      "source": [
        "### ***Import các thư viện cần thiết***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOR4tIyWxCtG"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import namedtuple\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS5NUyqriqjn"
      },
      "source": [
        "### ***Clone git để lấy dữ liệu ảnh train và test***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVMBQrJ-TkpR",
        "outputId": "6185861d-0acd-4432-f235-bae13fbd7f3a"
      },
      "source": [
        "# Mount với drive để lấy datasets \n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Link git lấy dataset \n",
        "!git clone https://github.com/quangtrung0220/SieuAmTim.git\n",
        "traindir = \"/content/SieuAmTim/DATA_CHAMBER_2021/train\"\n",
        "testdir = \"/content/SieuAmTim/DATA_CHAMBER_2021/test\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SieuAmTim'...\n",
            "remote: Enumerating objects: 8346, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 8346 (delta 4), reused 17 (delta 3), pack-reused 8328\u001b[K\n",
            "Receiving objects: 100% (8346/8346), 488.04 MiB | 26.75 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Checking out files: 100% (8328/8328), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGn9YjaGi51f"
      },
      "source": [
        "### ***Lấy ra các nhãn - classes và chuẩn bị dữ liệu***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   Các nhãn: 2C, 3C, 4C\n",
        "*   Các loại kích cỡ ảnh train và test: 224x224, 32x32\n",
        "*   Preprocess: Cân bằng sáng: histogram, Lọc nhiễu: GaussianBlur\n",
        "*   Data Augmentation: RandomCrop, RandomHorizontalFlip, RandomVerticalFlip\n",
        "*   Đưa vào batch để tận dụng khả năng xử lý song song của GPU\n",
        "*   Folder train và test lần lượt trong: traindir và testdir\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Ekbuc8UWLr"
      },
      "source": [
        "# Hàm lấy ra các classes\n",
        "def get_clases():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "\n",
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "# Hàm chuẩn bị dữ liệu\n",
        "def prepare_data():\n",
        "\n",
        "  # Preprocess\n",
        "  gaussianBlur = transforms.GaussianBlur(3)\n",
        "  histogramEqualize = transforms.RandomEqualize(p=0.5)\n",
        "\n",
        "  # #Normalize\n",
        "  # norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "  #      std=[0.229, 0.224, 0.225])\n",
        "\n",
        "  #Augmentation for all\n",
        "  horizontal = transforms.RandomHorizontalFlip()\n",
        "  vertical = transforms.RandomVerticalFlip()\n",
        "\n",
        "  #Image 224x224\n",
        "  resize_224 = transforms.Resize((224,224))\n",
        "  crop_224 = transforms.RandomCrop(224, padding=4)\n",
        "  \n",
        "  #Image 32x32\n",
        "  resize_32 = transforms.Resize((32,32))\n",
        "  crop_32 = transforms.RandomCrop(32, padding=4)\n",
        "\n",
        "  #To tensor\n",
        "  tensor = transforms.ToTensor()\n",
        "\n",
        "  #Raw image\n",
        "  transform_train_raw224 = transforms.Compose([resize_224, tensor])\n",
        "  transform_train_raw232 = transforms.Compose([resize_32, tensor])\n",
        "\n",
        "  #Augmentation image\n",
        "  transform_train_aug224 = transforms.Compose([resize_224, crop_224, horizontal, vertical, tensor])\n",
        "  transform_train_aug32 = transforms.Compose([resize_32, crop_32, horizontal, vertical, tensor])\n",
        "\n",
        "  #Preprocess image\n",
        "  transform_train_pre224 = transforms.Compose([resize_224, gaussianBlur, histogramEqualize, tensor])\n",
        "  transform_train_pre32 = transforms.Compose([resize_32, gaussianBlur, histogramEqualize, tensor])\n",
        "\n",
        "  #Test image\n",
        "  transform_test_224 = transforms.Compose([resize_224, tensor])\n",
        "  transform_test_32 = transforms.Compose([resize_32, tensor])\n",
        "\n",
        "  # transform_test = transforms.Compose([\n",
        "  #   transforms.Resize((224,224)),\n",
        "  #   # transforms.Resize((32,32)),\n",
        "\n",
        "  #   # Preprocess\n",
        "  #   transforms.GaussianBlur(3),\n",
        "  #   transforms.RandomEqualize(p=0.5),\n",
        "\n",
        "  #   transforms.ToTensor(),\n",
        "  #   transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "  #      std=[0.229, 0.224, 0.225])\n",
        "  # ])\n",
        "  trainset = torchvision.datasets.ImageFolder(root=traindir, transform=transform_train_aug224)\n",
        "  testset = torchvision.datasets.ImageFolder(root=testdir, transform=transform_test_224)\n",
        "  return TrainTest(train=trainset, test=testset)\n",
        "\n",
        "# Hàm load dữ liệu\n",
        "def prepare_loader(datasets):\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=35, shuffle=True, num_workers=4)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=35, shuffle=False, num_workers=4)\n",
        "  return TrainTest(train=trainloader, test=testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYQS8gvZqB6F"
      },
      "source": [
        "### ***Hàm train và test***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   BatchSize = 35\n",
        "*   Report sau mỗi 20 epoch \n",
        "*   Train: cho đi qua model và tính lỗi bằng loss_func sau đó cập nhật tham số mới\n",
        "*   Test: khai báo chế độ eval(đánh giá - evaluate) và trả về nhãn dự đoán và nhãn thực tếtế\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5aaQjZ6q7tM"
      },
      "source": [
        "# Data = prepare_data()\n",
        "# img, label = Data.train[3000]\n",
        "# print(label)\n",
        "# plt.show(img)\n",
        "# print(img)\n",
        "# s = Data.train.imgs[0]\n",
        "# print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBdgazuRRB3K"
      },
      "source": [
        "# Hàm train \n",
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  true_result = []\n",
        "  pred_result = []\n",
        "\n",
        "  # gọi hàm train để model biết mình phải cần huấn luyện \n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 20\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    true_result += list(labels.cpu().numpy())\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    pred_result += list(predicted.cpu().numpy())\n",
        "    # Tính lỗi \n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % reporting_steps == reporting_steps-1:\n",
        "      print(f\"Epoch {epoch} step {i} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "  # return pred_result, true_result\n",
        "\n",
        "# hàm test \n",
        "def test_epoch(epoch, model, loader, device):\n",
        "  ytrue = []\n",
        "  ypred = []\n",
        "  # Gọi hàm eval để model biết đang ở chế độ test \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    \n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "      ytrue += list(labels.cpu().numpy())\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "\n",
        "  return ypred, ytrue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e21jIMWPrUsA"
      },
      "source": [
        "### ***Hàm main***\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*   model_in = 'vgg16', 'resnet50' hoặc 'desnet': tên mạng Cnn đùng để huấn luyện\n",
        "*   PATH: đường dẫn lưu trọng số sau khi huấn luyện\n",
        "*   Đặc trưng ra = 3 vì có 3 lớp 2C, 3C, 4C\n",
        "*   Hàm lỗi được sử dụng: Cross-Entropy\n",
        "*   Hàm tối ưu đước sử dụng: SGD - Stochastic Gradient Descent\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA-A25O0RLTG",
        "outputId": "3a8bb4d2-f991-4c12-c921-f0fdd791208a"
      },
      "source": [
        "def main(PATH='./model.pth', model_in=''):\n",
        "  classes = get_clases()\n",
        "  datasets = prepare_data()\n",
        "  # img, label = datasets.train[0]\n",
        "  # plt.imshow(img)\n",
        "  # print(classes[label], img.size)\n",
        "  # print('train', len(datasets.train), 'test', len(datasets.test))\n",
        "  \n",
        "  loaders = prepare_loader(datasets)\n",
        "\n",
        "  # images, labels = iter(loaders.train).next()\n",
        "  # print(images.shape, labels.shape)\n",
        "\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # model = ResNet50().to(device)\n",
        "  # model = VGG16().to(device)\n",
        "  # images, labels = iter(loaders.train).next()\n",
        "  # outputs = model(images)\n",
        "  # print(outputs.shape)\n",
        "  # print(outputs[0])\n",
        "  # _, predicted = torch.max(outputs, dim=1)\n",
        "  # print(predicted)\n",
        "  # imshow(images, labels, predicted, classes)\n",
        "\n",
        "# Load model \n",
        "  if model_in == 'vgg16':\n",
        "    model = torchvision.models.vgg16()\n",
        "    model.classifier[6] = torch.nn.modules.linear.Linear(in_features=4096, out_features=3, bias=True)\n",
        "    # if torch.cuda.is_available():\n",
        "    model.to(device=device)\n",
        "  elif model_in == 'resnet50':\n",
        "    model = torchvision.models.resnet50(pretrained=False, progress=False)\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=2048, out_features=3, bias=True)  \n",
        "    # if torch.cuda.is_available():\n",
        "    model.to(device=device)\n",
        "  elif model_in == 'desnet':\n",
        "    model = torchvision.models.densenet121(pretrained=False, progress=False)\n",
        "    model.classifier = torch.nn.modules.linear.Linear(in_features=1024, out_features=3, bias=True)\n",
        "    # if torch.cuda.is_available():\n",
        "    model.to(device=device)\n",
        "  else:\n",
        "    pass  \n",
        "\n",
        "  # array_accuracy = []\n",
        "\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "  for epoch in range(10):\n",
        "    print(f'Epoch {epoch} report: ')\n",
        "    \n",
        "    # pred_result, true_result = \n",
        "    train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    # print('Train report: ')\n",
        "    # print(classification_report(true_result, pred_result, target_names=classes))\n",
        "\n",
        "    print('Test report: ')\n",
        "    ypred, ytrue = test_epoch(epoch, model, loaders.test, device)\n",
        "\n",
        "    # accuracy = (ytrue_test==ypred_test).sum() / len(ytrue_test)\n",
        "    # array_accuracy.append(accuracy)\n",
        "\n",
        "    print(classification_report(ytrue, ypred, target_names=classes))\n",
        "\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = main(PATH=\"./vgg16.pth\", model_in='vgg16')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 report: \n",
            "Epoch 0 step 19 ave_loss 1.0997\n",
            "Epoch 0 step 39 ave_loss 1.0959\n",
            "Epoch 0 step 59 ave_loss 1.0969\n",
            "Epoch 0 step 79 ave_loss 1.0857\n",
            "Epoch 0 step 99 ave_loss 1.0824\n",
            "Epoch 0 step 119 ave_loss 1.0837\n",
            "Epoch 0 step 139 ave_loss 1.0739\n",
            "Epoch 0 step 159 ave_loss 1.0651\n",
            "Epoch 0 step 179 ave_loss 1.0420\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.38      0.88      0.53       409\n",
            "          3C       1.00      0.04      0.07       367\n",
            "          4C       0.69      0.53      0.60       831\n",
            "\n",
            "    accuracy                           0.51      1607\n",
            "   macro avg       0.69      0.48      0.40      1607\n",
            "weighted avg       0.68      0.51      0.46      1607\n",
            "\n",
            "Epoch 1 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 step 19 ave_loss 1.0015\n",
            "Epoch 1 step 39 ave_loss 0.9567\n",
            "Epoch 1 step 59 ave_loss 0.9557\n",
            "Epoch 1 step 79 ave_loss 0.9997\n",
            "Epoch 1 step 99 ave_loss 0.9371\n",
            "Epoch 1 step 119 ave_loss 0.8417\n",
            "Epoch 1 step 139 ave_loss 0.8930\n",
            "Epoch 1 step 159 ave_loss 0.7228\n",
            "Epoch 1 step 179 ave_loss 0.7327\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.48      1.00      0.65       409\n",
            "          3C       0.70      0.29      0.41       367\n",
            "          4C       0.95      0.70      0.81       831\n",
            "\n",
            "    accuracy                           0.68      1607\n",
            "   macro avg       0.71      0.66      0.62      1607\n",
            "weighted avg       0.78      0.68      0.68      1607\n",
            "\n",
            "Epoch 2 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 step 19 ave_loss 0.6951\n",
            "Epoch 2 step 39 ave_loss 0.6226\n",
            "Epoch 2 step 59 ave_loss 0.4956\n",
            "Epoch 2 step 79 ave_loss 0.4903\n",
            "Epoch 2 step 99 ave_loss 0.4979\n",
            "Epoch 2 step 119 ave_loss 0.5648\n",
            "Epoch 2 step 139 ave_loss 0.4870\n",
            "Epoch 2 step 159 ave_loss 0.3352\n",
            "Epoch 2 step 179 ave_loss 0.3823\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.67      0.85      0.75       409\n",
            "          3C       0.65      0.37      0.47       367\n",
            "          4C       0.86      0.91      0.89       831\n",
            "\n",
            "    accuracy                           0.77      1607\n",
            "   macro avg       0.73      0.71      0.70      1607\n",
            "weighted avg       0.76      0.77      0.76      1607\n",
            "\n",
            "Epoch 3 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 step 19 ave_loss 0.3981\n",
            "Epoch 3 step 39 ave_loss 0.3579\n",
            "Epoch 3 step 59 ave_loss 0.3227\n",
            "Epoch 3 step 79 ave_loss 0.2700\n",
            "Epoch 3 step 99 ave_loss 0.2720\n",
            "Epoch 3 step 119 ave_loss 0.2214\n",
            "Epoch 3 step 139 ave_loss 0.1754\n",
            "Epoch 3 step 159 ave_loss 0.2590\n",
            "Epoch 3 step 179 ave_loss 0.2052\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.67      0.91      0.77       409\n",
            "          3C       0.56      0.83      0.67       367\n",
            "          4C       0.96      0.59      0.73       831\n",
            "\n",
            "    accuracy                           0.72      1607\n",
            "   macro avg       0.73      0.77      0.72      1607\n",
            "weighted avg       0.80      0.72      0.73      1607\n",
            "\n",
            "Epoch 4 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 step 19 ave_loss 0.1612\n",
            "Epoch 4 step 39 ave_loss 0.1830\n",
            "Epoch 4 step 59 ave_loss 0.2126\n",
            "Epoch 4 step 79 ave_loss 0.1477\n",
            "Epoch 4 step 99 ave_loss 0.1865\n",
            "Epoch 4 step 119 ave_loss 0.1587\n",
            "Epoch 4 step 139 ave_loss 0.1507\n",
            "Epoch 4 step 159 ave_loss 0.1171\n",
            "Epoch 4 step 179 ave_loss 0.1391\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.64      0.93      0.76       409\n",
            "          3C       0.55      0.71      0.62       367\n",
            "          4C       0.96      0.62      0.75       831\n",
            "\n",
            "    accuracy                           0.72      1607\n",
            "   macro avg       0.72      0.75      0.71      1607\n",
            "weighted avg       0.78      0.72      0.72      1607\n",
            "\n",
            "Epoch 5 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 step 19 ave_loss 0.0898\n",
            "Epoch 5 step 39 ave_loss 0.0999\n",
            "Epoch 5 step 59 ave_loss 0.1042\n",
            "Epoch 5 step 79 ave_loss 0.0890\n",
            "Epoch 5 step 99 ave_loss 0.0644\n",
            "Epoch 5 step 119 ave_loss 0.0882\n",
            "Epoch 5 step 139 ave_loss 0.1492\n",
            "Epoch 5 step 159 ave_loss 0.0721\n",
            "Epoch 5 step 179 ave_loss 0.0797\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.70      0.96      0.81       409\n",
            "          3C       0.66      0.83      0.73       367\n",
            "          4C       0.97      0.68      0.80       831\n",
            "\n",
            "    accuracy                           0.78      1607\n",
            "   macro avg       0.77      0.82      0.78      1607\n",
            "weighted avg       0.83      0.78      0.79      1607\n",
            "\n",
            "Epoch 6 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 step 19 ave_loss 0.0643\n",
            "Epoch 6 step 39 ave_loss 0.0982\n",
            "Epoch 6 step 59 ave_loss 0.0802\n",
            "Epoch 6 step 79 ave_loss 0.0651\n",
            "Epoch 6 step 99 ave_loss 0.0798\n",
            "Epoch 6 step 119 ave_loss 0.0982\n",
            "Epoch 6 step 139 ave_loss 0.0784\n",
            "Epoch 6 step 159 ave_loss 0.0217\n",
            "Epoch 6 step 179 ave_loss 0.0511\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.59      0.80      0.68       409\n",
            "          3C       0.56      0.70      0.62       367\n",
            "          4C       0.97      0.70      0.81       831\n",
            "\n",
            "    accuracy                           0.72      1607\n",
            "   macro avg       0.71      0.73      0.70      1607\n",
            "weighted avg       0.78      0.72      0.73      1607\n",
            "\n",
            "Epoch 7 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 step 19 ave_loss 0.0521\n",
            "Epoch 7 step 39 ave_loss 0.0114\n",
            "Epoch 7 step 59 ave_loss 0.0555\n",
            "Epoch 7 step 79 ave_loss 0.0703\n",
            "Epoch 7 step 99 ave_loss 0.0415\n",
            "Epoch 7 step 119 ave_loss 0.0298\n",
            "Epoch 7 step 139 ave_loss 0.0406\n",
            "Epoch 7 step 159 ave_loss 0.0402\n",
            "Epoch 7 step 179 ave_loss 0.0293\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.55      0.98      0.70       409\n",
            "          3C       0.76      0.77      0.76       367\n",
            "          4C       0.98      0.60      0.75       831\n",
            "\n",
            "    accuracy                           0.73      1607\n",
            "   macro avg       0.76      0.78      0.74      1607\n",
            "weighted avg       0.82      0.73      0.74      1607\n",
            "\n",
            "Epoch 8 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 step 19 ave_loss 0.0205\n",
            "Epoch 8 step 39 ave_loss 0.0619\n",
            "Epoch 8 step 59 ave_loss 0.0421\n",
            "Epoch 8 step 79 ave_loss 0.0294\n",
            "Epoch 8 step 99 ave_loss 0.0164\n",
            "Epoch 8 step 119 ave_loss 0.0342\n",
            "Epoch 8 step 139 ave_loss 0.0479\n",
            "Epoch 8 step 159 ave_loss 0.0332\n",
            "Epoch 8 step 179 ave_loss 0.0169\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.74      0.72      0.73       409\n",
            "          3C       0.65      0.92      0.76       367\n",
            "          4C       0.94      0.78      0.86       831\n",
            "\n",
            "    accuracy                           0.80      1607\n",
            "   macro avg       0.78      0.81      0.78      1607\n",
            "weighted avg       0.82      0.80      0.80      1607\n",
            "\n",
            "Epoch 9 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 step 19 ave_loss 0.0171\n",
            "Epoch 9 step 39 ave_loss 0.0124\n",
            "Epoch 9 step 59 ave_loss 0.0359\n",
            "Epoch 9 step 79 ave_loss 0.0485\n",
            "Epoch 9 step 99 ave_loss 0.0284\n",
            "Epoch 9 step 119 ave_loss 0.0393\n",
            "Epoch 9 step 139 ave_loss 0.0357\n",
            "Epoch 9 step 159 ave_loss 0.0190\n",
            "Epoch 9 step 179 ave_loss 0.0080\n",
            "Test report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.64      0.98      0.77       409\n",
            "          3C       0.66      0.80      0.72       367\n",
            "          4C       0.97      0.63      0.76       831\n",
            "\n",
            "    accuracy                           0.76      1607\n",
            "   macro avg       0.76      0.80      0.75      1607\n",
            "weighted avg       0.82      0.76      0.76      1607\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgCHbCeyxakr"
      },
      "source": [
        "# Kết quả sau 10 epoch:\n",
        "\n",
        "# Train_Accuracy:\n",
        "# VGG16_Ảnh resize 224: [35, 38, 38, 41, 54, 70, 82, 89, 93, 95]\n",
        "# VGG16_Ảnh resize 32: [36, 42, 54, 65, 81, 89, 92, 94, 97, 97]\n",
        "# ResNet50_Ảnh resize 224: [35, 38, 38, 41, 54, 70, 82, 89, 93, 95]\n",
        "# Desnet121_Ảnh resize 224: [68, 93, 97, 99, 99, 99, 100, 100, 100, 100]\n",
        "# Desnet121_Ảnh resize 32: [63, 80, 91, 94, 97, 97, 97, 98, 98, 99]\n",
        "\n",
        "# Test_Accuracy\n",
        "# VGG16_Ảnh resize 224: [32, 25, 27, 48, 66, 62, 92, 90, 85, 87]\n",
        "# VGG16_Ảnh resize 32: [23, 56, 63, 74, 82, 83, 87, 85, 91, 83]\n",
        "# ResNet50_Ảnh resize 224: [35, 38, 38, 41, 54, 70, 82, 89, 93, 95]\n",
        "# Desnet121_Ảnh resize 224: [66, 71, 78, 74, 74, 72, 82, 87, 87, 88]\n",
        "# Desnet121_Ảnh resize 32: [78, 83, 79, 78, 77, 72, 70, 78, 78, 82]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}