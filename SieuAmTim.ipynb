{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SieuAmTim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quangtrung0220/SieuAmTim/blob/master/SieuAmTim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOR4tIyWxCtG"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import namedtuple\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVMBQrJ-TkpR",
        "outputId": "5a0fc9d0-126a-41d7-a465-45b2eb50fb9f"
      },
      "source": [
        "# Mount với drive để lấy datasets \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Ekbuc8UWLr"
      },
      "source": [
        "# Hàm lấy ra các classes\n",
        "def get_clases():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "\n",
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "# Hàm chuẩn bị dữ liệu\n",
        "def prepare_data():\n",
        "  transform_train = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    # transforms.Resize((32,32)),                                    \n",
        "    # transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "  transform_test = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    # transforms.Resize((32,32)),\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "  trainset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/train', transform=transform_train)\n",
        "  testset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/test', transform=transform_test)\n",
        "  return TrainTest(train=trainset, test=testset)\n",
        "\n",
        "# Hàm load dữ liệu\n",
        "def prepare_loader(datasets):\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=35, shuffle=True, num_workers=4)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=35, shuffle=False, num_workers=4)\n",
        "  return TrainTest(train=trainloader, test=testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5aaQjZ6q7tM"
      },
      "source": [
        "# Data = prepare_data()\n",
        "# img, label = Data.train[3000]\n",
        "# print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBdgazuRRB3K"
      },
      "source": [
        "# Hàm train \n",
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  true_result = []\n",
        "  pred_result = []\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 18\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    true_result += list(labels.cpu().numpy())\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    pred_result += list(predicted.cpu().numpy())\n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % reporting_steps == reporting_steps-1:\n",
        "      print(f\"Epoch {epoch} step {i} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "  return pred_result, true_result\n",
        "\n",
        "# hàm test \n",
        "def test_epoch(epoch, model, loader, device):\n",
        "  ytrue = []\n",
        "  ypred = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    \n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "      ytrue += list(labels.cpu().numpy())\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "\n",
        "  return ypred, ytrue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA-A25O0RLTG"
      },
      "source": [
        "def main(PATH='./model.pth', model_in=''):\n",
        "  classes = get_clases()\n",
        "  datasets = prepare_data()\n",
        "  # img, label = datasets.train[0]\n",
        "  # plt.imshow(img)\n",
        "  # print(classes[label], img.size)\n",
        "  # print('train', len(datasets.train), 'test', len(datasets.test))\n",
        "  \n",
        "  loaders = prepare_loader(datasets)\n",
        "\n",
        "  # images, labels = iter(loaders.train).next()\n",
        "  # print(images.shape, labels.shape)\n",
        "\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # model = ResNet50().to(device)\n",
        "  # model = VGG16().to(device)\n",
        "  # images, labels = iter(loaders.train).next()\n",
        "  # outputs = model(images)\n",
        "  # print(outputs.shape)\n",
        "  # print(outputs[0])\n",
        "  # _, predicted = torch.max(outputs, dim=1)\n",
        "  # print(predicted)\n",
        "  # imshow(images, labels, predicted, classes)\n",
        "\n",
        "# Load model \n",
        "  if model_in == 'vgg16':\n",
        "    model = torchvision.models.vgg16()\n",
        "    model.classifier[6] = torch.nn.modules.linear.Linear(in_features=4096, out_features=3, bias=True)\n",
        "    if torch.cuda.is_available():\n",
        "      model.to(device=device)\n",
        "  elif model_in == 'resnet50':\n",
        "    model = torchvision.models.resnet50(pretrained=False, progress=False)\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=2048, out_features=3, bias=True)  \n",
        "    if torch.cuda.is_available():\n",
        "      model.to(device=device)\n",
        "  elif model_in == 'desnet':\n",
        "    model = torchvision.models.densenet121(pretrained=False, progress=False)\n",
        "    model.classifier = torch.nn.modules.linear.Linear(in_features=1024, out_features=3, bias=True)\n",
        "    if torch.cuda.is_available():\n",
        "      model.to(device=device)\n",
        "  else:\n",
        "    pass  \n",
        "\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "  for epoch in range(10):\n",
        "    print(f'Epoch {epoch} report: ')\n",
        "    \n",
        "    pred_result, true_result = train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    print('Train report: ')\n",
        "    print(classification_report(true_result, pred_result, target_names=classes))\n",
        "\n",
        "    print('Test report: ')\n",
        "    ypred, ytrue = test_epoch(epoch, model, loaders.test, device)\n",
        "    print(classification_report(ytrue, ypred, target_names=classes))\n",
        "\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = main(PATH=\"./resnet50.pth\", model_in='resnet50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgCHbCeyxakr"
      },
      "source": [
        "Kết quả sau 10 epoch:\n",
        "\n",
        "Train_Accuracy:\n",
        "VGG16_Ảnh resize 224: [35, 38, 38, 41, 54, 70, 82, 89, 93, 95]\n",
        "VGG16_Ảnh resize 32: [36, 42, 54, 65, 81, 89, 92, 94, 97, 97]\n",
        "ResNet50_Ảnh resize 224: [35, 38, 38, 41, 54, 70, 82, 89, 93, 95]\n",
        "Desnet121_Ảnh resize 224: [68, 93, 97, 99, 99, 99, 100, 100, 100, 100]\n",
        "Desnet121_Ảnh resize 32: [63, 80, 91, 94, 97, 97, 97, 98, 98, 99]\n",
        "\n",
        "Test_Accuracy\n",
        "VGG16_Ảnh resize 224: [32, 25, 27, 48, 66, 62, 92, 90, 85, 87]\n",
        "VGG16_Ảnh resize 32: [23, 56, 63, 74, 82, 83, 87, 85, 91, 83]\n",
        "ResNet50_Ảnh resize 224: [35, 38, 38, 41, 54, 70, 82, 89, 93, 95]\n",
        "Desnet121_Ảnh resize 224: [66, 71, 78, 74, 74, 72, 82, 87, 87, 88]\n",
        "Desnet121_Ảnh resize 32: [78, 83, 79, 78, 77, 72, 70, 78, 78, 82]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}